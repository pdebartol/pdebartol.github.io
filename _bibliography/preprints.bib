@article{debartolomeis2025efficient,
  title={Efficient Randomized Experiments Using Foundation Models},
  author={Piersilvio De Bartolomeis and Javier Abad and Guanbo Wang and Konstantin Donhauser and Raymond M. Duch and Fanny Yang and Issa J. Dahabreh},
  conference={arXiv preprint,},
  year={2025},
  arxiv={https://arxiv.org/abs/2502.04262},
  code = {https://github.com/jaabmar/HAIPW},
  video = {https://carswg.github.io/journalclub/journalclub12.html},
  selected={true},
  abstract={Randomized experiments are the preferred approach for evaluating the effects of interventions, but they are costly and often yield estimates with substantial uncertainty. On the other hand, in silico experiments leveraging foundation models offer a cost-effective alternative that can potentially attain higher statistical precision. However, the benefits of in silico experiments come with a significant risk: statistical inferences are not valid if the models fail to accurately predict experimental responses to interventions. In this paper, we propose a novel approach that integrates the predictions from multiple foundation models with experimental data while preserving valid statistical inference. Our estimator is consistent and asymptotically normal, with asymptotic variance no larger than the standard estimator based on experimental data alone. Importantly, these statistical properties hold even when model predictions are arbitrarily biased. Empirical results across several randomized experiments show that our estimator offers substantial precision gains, equivalent to a reduction of up to 20% in the sample size needed to match the same precision as the standard estimator based on experimental data alone.}
}

@article{cadei2025causal,
  title={Causal Lifting of Neural Representations: Zero-Shot Generalization for Causal Inferences},
  author={Cadei, Riccardo and Demirel*, Ilker and De Bartolomeis*, Piersilvio and Lindorfer, Lukas and Cremer, Sylvia and Schmid, Cordelia and Locatello, Francesco},
  conference={arXiv preprint,},
  year={2025},
  arxiv={https://arxiv.org/abs/2502.06343},
  abstract={A plethora of real-world scientific investigations is waiting to scale with the support of trustworthy predictive models that can reduce the need for costly data annotations. We focus on causal inferences on a target experiment with unlabeled factual outcomes, retrieved by a predictive model fine-tuned on a labeled similar experiment. First, we show that factual outcome estimation via Empirical Risk Minimization (ERM) may fail to yield valid causal inferences on the target population, even in a randomized controlled experiment and infinite training samples. Then, we propose to leverage the observed experimental settings during training to empower generalization to downstream interventional investigations, ``Causal Lifting'' the predictive model. We propose Deconfounded Empirical Risk Minimization (DERM), a new simple learning procedure minimizing the risk over a fictitious target population, preventing potential confounding effects. We validate our method on both synthetic and real-world scientific data. Notably, for the first time, we zero-shot generalize causal inferences on ISTAnt dataset (without annotation) by causal lifting a predictive model on our experiment variant.}

}